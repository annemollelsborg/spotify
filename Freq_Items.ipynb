{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequent Items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "- Load cleaned data and user data with clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from scipy.sparse import csr_matrix\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "from collections import Counter\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_songs = \"Data/df_combined.csv\"\n",
    "df_songs = pd.read_csv(file_path_songs)\n",
    "file_path_clusters = \"Data/df_users.csv\"\n",
    "df_users = pd.read_csv(file_path_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute market basket data frames\n",
    "- A market basket data frame is computed for each cluster\n",
    "- Only users with more than 50 total listenings are included\n",
    "- Each basket includes at most the users 100 most played songs\n",
    "- Songs which does not occur in more than 10 different baskets are excluded\n",
    "\n",
    "We generate 15 separate DataFrames stored as `df_basket_1`, `df_basket_2`, ..., `df_basket_15`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total play count for each user\n",
    "user_total_playcount = df_users.groupby('user_id')['playcount'].sum().reset_index()\n",
    "user_total_playcount = user_total_playcount[user_total_playcount['playcount'] >= 50]\n",
    "\n",
    "# Filter the original user data to include only users with at least 50 total plays\n",
    "df_users_filtered = df_users[df_users['user_id'].isin(user_total_playcount['user_id'])]\n",
    "\n",
    "# Process each cluster to generate individual DataFrames\n",
    "cluster_dataframes = {}  # Dictionary to hold the dataframes for each cluster\n",
    "\n",
    "for cluster_id in sorted(df_users_filtered['most_played_cluster'].unique()[:15]):  # Ensure max 15 clusters\n",
    "    # Filter the data for the current cluster\n",
    "    cluster_data = df_users_filtered[df_users_filtered['most_played_cluster'] == cluster_id]\n",
    "\n",
    "    # Sort songs for each user by play count and select the 100 most played songs\n",
    "    def get_top_songs(user_data):\n",
    "        return user_data.nlargest(100, 'playcount')  # Adjust to desired number of top songs\n",
    "\n",
    "    # Apply the top song selection for each user\n",
    "    df_top_songs_cluster = cluster_data.groupby('user_id').apply(get_top_songs).reset_index(drop=True)\n",
    "\n",
    "    # Create a basket for each user with their top songs\n",
    "    df_basket_cluster = df_top_songs_cluster.groupby('user_id')['track_id'].apply(list).reset_index()\n",
    "    df_basket_cluster.rename(columns={'track_id': 'basket'}, inplace=True)\n",
    "\n",
    "    # Assign the DataFrame to a variable dynamically\n",
    "    cluster_dataframes[f\"df_basket_{cluster_id}\"] = df_basket_cluster\n",
    "\n",
    "    # Optionally, save to a named variable\n",
    "    globals()[f\"df_basket_{cluster_id}\"] = df_basket_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter songs occurring in more than 10 baskets\n",
    "def filter_songs(df_basket, min_basket_count=10):\n",
    "    \"\"\"\n",
    "    Filters out songs from the baskets that occur in fewer than `min_basket_count` baskets.\n",
    "    \n",
    "    Parameters:\n",
    "    - df_basket (pd.DataFrame): DataFrame with columns `user_id` and `basket`.\n",
    "    - min_basket_count (int): Minimum number of baskets a song must appear in to be retained.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Filtered DataFrame with updated baskets.\n",
    "    \"\"\"\n",
    "    # Flatten all baskets into a single list to count song occurrences\n",
    "    all_songs = [song for basket in df_basket['basket'] for song in basket]\n",
    "    song_counts = Counter(all_songs)\n",
    "\n",
    "    # Identify songs that occur in more than `min_basket_count` baskets\n",
    "    frequent_songs = {song for song, count in song_counts.items() if count > min_basket_count}\n",
    "\n",
    "    # Filter each user's basket to retain only frequent songs\n",
    "    df_basket['basket'] = df_basket['basket'].apply(lambda basket: [song for song in basket if song in frequent_songs])\n",
    "\n",
    "    # Remove rows with empty baskets\n",
    "    df_basket = df_basket[df_basket['basket'].map(len) > 0].reset_index(drop=True)\n",
    "\n",
    "    return df_basket\n",
    "\n",
    "# Apply the function to each df_basket_# DataFrame\n",
    "for cluster_id in cluster_dataframes.keys():\n",
    "    cluster_dataframes[cluster_id] = filter_songs(cluster_dataframes[cluster_id])\n",
    "\n",
    "    # Optionally, save back to dynamically created variables\n",
    "    globals()[cluster_id] = cluster_dataframes[cluster_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute association rules and support\n",
    "- Support and association rules are computed for each basket data frame\n",
    "- The minimum support used is 2%\n",
    "- Association rules are computed using the Apriori algorithm to generate frequent single items, dublets, and triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate support for itemsets\n",
    "def calculate_support(data, itemsets):\n",
    "    itemset_counts = defaultdict(int)\n",
    "    for basket in data['basket']:\n",
    "        for itemset in itemsets:\n",
    "            if set(itemset).issubset(set(basket)):\n",
    "                itemset_counts[itemset] += 1\n",
    "    total_baskets = len(data)\n",
    "    support = {itemset: count / total_baskets for itemset, count in itemset_counts.items()}\n",
    "    return support\n",
    "\n",
    "# Apriori Algorithm for Size 2 and 3\n",
    "def apriori_pairs_and_triplets(data, min_support):\n",
    "    frequent_itemsets = {}\n",
    "\n",
    "    # Start with single items\n",
    "    items = set(item for basket in data['basket'] for item in basket)\n",
    "    single_itemsets = [(item,) for item in items]\n",
    "    \n",
    "    # Calculate support for single items\n",
    "    support = calculate_support(data, single_itemsets)\n",
    "    frequent_singles = [itemset for itemset, sup in support.items() if sup >= min_support]\n",
    "    frequent_itemsets.update({itemset: support[itemset] for itemset in frequent_singles})\n",
    "    \n",
    "    print(f\"Frequent Single Items: {frequent_singles}\")\n",
    "    \n",
    "    # Generate pairs (size 2)\n",
    "    pairs = list(combinations(set(item for itemset in frequent_singles for item in itemset), 2))\n",
    "    pair_support = calculate_support(data, pairs)\n",
    "    frequent_pairs = [itemset for itemset, sup in pair_support.items() if sup >= min_support]\n",
    "    frequent_itemsets.update({itemset: pair_support[itemset] for itemset in frequent_pairs})\n",
    "    \n",
    "    print(f\"Frequent Pairs: {frequent_pairs}\")\n",
    "    \n",
    "    # Generate triplets (size 3)\n",
    "    triplets = list(combinations(set(item for itemset in frequent_pairs for item in itemset), 3))\n",
    "    triplet_support = calculate_support(data, triplets)\n",
    "    frequent_triplets = [itemset for itemset, sup in triplet_support.items() if sup >= min_support]\n",
    "    frequent_itemsets.update({itemset: triplet_support[itemset] for itemset in frequent_triplets})\n",
    "    \n",
    "    print(f\"Frequent Triplets: {frequent_triplets}\")\n",
    "    \n",
    "    return frequent_itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate results (freq. items and support)\n",
    "The frequent items and item sets with corresponding support are stored in a CSV file for each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing df_basket_1...\n",
      "Frequent Single Items: [('TRRXGAK128EF349F1A',), ('TRRKGRC128F932D8F0',), ('TRWZFIC128F933BCA3',), ('TRNEWWX128F9336A1F',), ('TRUFTBY128F93450B8',), ('TRCPXID128F92D5D3C',), ('TRLUKKL128F4284EEA',), ('TRIJLQJ128E078F6F1',), ('TROYOWO12903CACF51',), ('TRUNCXA12903CDAA07',), ('TRBEFXF128F4263CE9',), ('TRONYHY128F92C9D11',), ('TRAZIQK12903CCFB3A',), ('TRRGWHY128F93043DB',), ('TRUDNRB128F42598CA',), ('TRBNYBX128F422EC61',), ('TRUWANM128F1485EE2',), ('TRSUNIO128F92DD214',), ('TRFKZHE128F149F632',), ('TRVZILF128F42748EF',), ('TRRGKHJ128F92F64DA',), ('TRBHVEV128F425C018',), ('TRMEBVU128F92F64DB',), ('TRCQFJI128F4284EEE',), ('TRFTUIW128E0784B9F',), ('TRQJLCO128F42BCC0A',), ('TRYFDNR128F4260C5E',), ('TRPDNZQ128F92C1E98',), ('TRXHXZJ128F92DD518',), ('TREXRIW128EF3434B7',), ('TRETTHQ128F428294E',), ('TRERZDK128F42B3222',), ('TRIXKCB128F424EA32',), ('TRZNAHL128F9327D5A',), ('TRIYBSB128F14B0259',), ('TRWCIAX128F42925BD',), ('TRFNGJS128F92F9EEE',), ('TRFWGOJ128E0780C8B',), ('TRPYYZN128F9304FBA',), ('TRHJBZP128F145F6A6',), ('TRSUSWW128F93463BF',), ('TRMVCVS128F1468256',), ('TRPFYYL128F92F7144',), ('TRAOIAH128F92F707B',), ('TRXYRWA128F92CDF2E',), ('TRCGAVX12903CFBC61',), ('TRUNRNB128F42A76B6',), ('TRUYKXX128F426C2F1',), ('TRPGPDK12903CCC651',), ('TRXBXZT128F42A8E06',), ('TRRIRMX128F92E6272',), ('TRWVOJJ12903CCC654',), ('TRAMFJR128F92C1DB1',), ('TRWTPYD12903D03AE9',), ('TRVSJOM12903CD2DC1',), ('TRCTYEY128F428E848',), ('TRDHBPQ128F425EA1E',), ('TROVEVL128F932A447',), ('TRHMVOQ128F1472E6D',), ('TROIBHC128F14958FC',), ('TRZBZRH128F92FFBFC',), ('TRRMVBR128F92F64BA',), ('TRHUNZT128C719654E',), ('TRISTGF12903D0DC6F',), ('TROQTGM128F426733C',), ('TRXWAZC128F9314B3E',), ('TROIRNZ12903CE5D91',), ('TRLRGVX128E078EC1B',), ('TRSGHGP12903CE520A',), ('TRAYVEL128F149F631',), ('TRAALAH128E078234A',), ('TRIXXYP128C7196826',), ('TROQETL128F4267337',), ('TRFRGTX12903CF7AB1',), ('TRZGLNO128F92D65BE',), ('TRRMGWC128F426733E',), ('TREBWYU12903CCDAA8',), ('TRRGZTI128F4255806',), ('TRUCRUF128F14B0255',), ('TRZALGW128F4296174',), ('TRWNPDZ128F934B946',), ('TROSQNP128F92C5073',), ('TRXLBFN128EF343BFE',), ('TRZNGII128C7196554',), ('TRRJQES128EF35675B',), ('TRXXCIZ128F42574DD',), ('TRABFDT12903CADD73',), ('TRLOHWT128F42598CF',), ('TRGCHLH12903CB7352',), ('TRIPUHC12903D03AFC',), ('TRLVQME128F931BAF3',), ('TRWAQOC12903CB84CA',), ('TRVSFYH128F42639B7',), ('TRZJEUW128F93456CB',), ('TRZXJMS128F4259AFC',), ('TRJAAFV128F426C35F',), ('TRNXZHW128F934B958',), ('TRGNDNE128F92E50F5',), ('TREHENJ128E07953C7',), ('TRAAKDG128F42A0ECB',), ('TRYYTUP128F4298472',), ('TRUEQWJ128F421CD83',), ('TRRVJCK12903CD2DCB',), ('TRZLEQU128F4259AFD',), ('TRMFXMQ128F4259B01',), ('TRKXOWA128EF3434B2',), ('TRBARSX12903D03AE5',), ('TREFMGX128F4259AFB',), ('TRDBYEH12903D03AF3',), ('TRGGDOF12903D03AEE',), ('TRBKFKL128E078ED76',), ('TRJJQNH128F92CEB62',), ('TRWIKBF128F92DD506',), ('TRRVSBS128F425A7B0',), ('TROMKCG128F9320C09',), ('TRASUJG128F92D6316',), ('TRLUROI128F92FFBFD',), ('TRYPVYH128F42A4C53',), ('TRSHTTA128F1469578',), ('TRXHAZS128F42598D1',), ('TRBJARK128F1465649',), ('TRXESGJ12903CC04D2',)]\n",
      "Frequent Pairs: [('TRUFTBY128F93450B8', 'TRCPXID128F92D5D3C'), ('TRMEBVU128F92F64DB', 'TRRGKHJ128F92F64DA'), ('TRETTHQ128F428294E', 'TRXHXZJ128F92DD518'), ('TRHMVOQ128F1472E6D', 'TROVEVL128F932A447'), ('TRHMVOQ128F1472E6D', 'TRFKZHE128F149F632'), ('TROVEVL128F932A447', 'TRFKZHE128F149F632'), ('TRRMVBR128F92F64BA', 'TRHUNZT128C719654E'), ('TRRMVBR128F92F64BA', 'TRMEBVU128F92F64DB'), ('TRRMVBR128F92F64BA', 'TRUYKXX128F426C2F1'), ('TRRMVBR128F92F64BA', 'TRWCIAX128F42925BD'), ('TRRMVBR128F92F64BA', 'TRRGKHJ128F92F64DA'), ('TRRMVBR128F92F64BA', 'TRISTGF12903D0DC6F'), ('TRHUNZT128C719654E', 'TRMEBVU128F92F64DB'), ('TRHUNZT128C719654E', 'TRUYKXX128F426C2F1'), ('TRHUNZT128C719654E', 'TRWCIAX128F42925BD'), ('TRHUNZT128C719654E', 'TRRGKHJ128F92F64DA'), ('TRHUNZT128C719654E', 'TRISTGF12903D0DC6F'), ('TRMEBVU128F92F64DB', 'TRUYKXX128F426C2F1'), ('TRMEBVU128F92F64DB', 'TRWCIAX128F42925BD'), ('TRMEBVU128F92F64DB', 'TRISTGF12903D0DC6F'), ('TRUYKXX128F426C2F1', 'TRWCIAX128F42925BD'), ('TRUYKXX128F426C2F1', 'TRRGKHJ128F92F64DA'), ('TRUYKXX128F426C2F1', 'TRISTGF12903D0DC6F'), ('TRWCIAX128F42925BD', 'TRRGKHJ128F92F64DA'), ('TRWCIAX128F42925BD', 'TRISTGF12903D0DC6F'), ('TRRGKHJ128F92F64DA', 'TRISTGF12903D0DC6F'), ('TRHMVOQ128F1472E6D', 'TRAYVEL128F149F631'), ('TRAYVEL128F149F631', 'TRFKZHE128F149F632'), ('TROVEVL128F932A447', 'TRAYVEL128F149F631'), ('TRRMVBR128F92F64BA', 'TRZNGII128C7196554'), ('TRZNGII128C7196554', 'TRHUNZT128C719654E'), ('TRZNGII128C7196554', 'TRMEBVU128F92F64DB'), ('TRZNGII128C7196554', 'TRWCIAX128F42925BD'), ('TRZNGII128C7196554', 'TRRGKHJ128F92F64DA'), ('TRZNGII128C7196554', 'TRISTGF12903D0DC6F'), ('TRRJQES128EF35675B', 'TRMEBVU128F92F64DB'), ('TRRMVBR128F92F64BA', 'TRUEQWJ128F421CD83'), ('TRHUNZT128C719654E', 'TRUEQWJ128F421CD83'), ('TRMEBVU128F92F64DB', 'TRUEQWJ128F421CD83'), ('TRWCIAX128F42925BD', 'TRUEQWJ128F421CD83'), ('TRRGKHJ128F92F64DA', 'TRUEQWJ128F421CD83'), ('TRUEQWJ128F421CD83', 'TRISTGF12903D0DC6F'), ('TRZLEQU128F4259AFD', 'TRUDNRB128F42598CA'), ('TRIPUHC12903D03AFC', 'TRWTPYD12903D03AE9'), ('TRIPUHC12903D03AFC', 'TRBARSX12903D03AE5'), ('TRWTPYD12903D03AE9', 'TRBARSX12903D03AE5'), ('TRVSFYH128F42639B7', 'TREXRIW128EF3434B7'), ('TRDBYEH12903D03AF3', 'TRIPUHC12903D03AFC'), ('TRDBYEH12903D03AF3', 'TRGGDOF12903D03AEE'), ('TRDBYEH12903D03AF3', 'TRWTPYD12903D03AE9'), ('TRDBYEH12903D03AF3', 'TRBARSX12903D03AE5'), ('TRIPUHC12903D03AFC', 'TRGGDOF12903D03AEE'), ('TRGGDOF12903D03AEE', 'TRWTPYD12903D03AE9'), ('TRLUROI128F92FFBFD', 'TRUDNRB128F42598CA'), ('TRLUROI128F92FFBFD', 'TRLOHWT128F42598CF'), ('TRUDNRB128F42598CA', 'TRLOHWT128F42598CF'), ('TRZLEQU128F4259AFD', 'TRXHAZS128F42598D1'), ('TRZLEQU128F4259AFD', 'TRLOHWT128F42598CF'), ('TRXHAZS128F42598D1', 'TRUDNRB128F42598CA'), ('TRXHAZS128F42598D1', 'TRLOHWT128F42598CF')]\n",
      "Frequent Triplets: [('TROVEVL128F932A447', 'TRHMVOQ128F1472E6D', 'TRFKZHE128F149F632'), ('TRRMVBR128F92F64BA', 'TRWCIAX128F42925BD', 'TRRGKHJ128F92F64DA'), ('TRRMVBR128F92F64BA', 'TRWCIAX128F42925BD', 'TRHUNZT128C719654E'), ('TRRMVBR128F92F64BA', 'TRWCIAX128F42925BD', 'TRMEBVU128F92F64DB'), ('TRRMVBR128F92F64BA', 'TRWCIAX128F42925BD', 'TRUYKXX128F426C2F1'), ('TRRMVBR128F92F64BA', 'TRWCIAX128F42925BD', 'TRISTGF12903D0DC6F'), ('TRRMVBR128F92F64BA', 'TRRGKHJ128F92F64DA', 'TRHUNZT128C719654E'), ('TRRMVBR128F92F64BA', 'TRRGKHJ128F92F64DA', 'TRMEBVU128F92F64DB'), ('TRRMVBR128F92F64BA', 'TRRGKHJ128F92F64DA', 'TRUYKXX128F426C2F1'), ('TRRMVBR128F92F64BA', 'TRRGKHJ128F92F64DA', 'TRISTGF12903D0DC6F'), ('TRRMVBR128F92F64BA', 'TRHUNZT128C719654E', 'TRMEBVU128F92F64DB'), ('TRRMVBR128F92F64BA', 'TRHUNZT128C719654E', 'TRUYKXX128F426C2F1'), ('TRRMVBR128F92F64BA', 'TRHUNZT128C719654E', 'TRISTGF12903D0DC6F'), ('TRRMVBR128F92F64BA', 'TRMEBVU128F92F64DB', 'TRUYKXX128F426C2F1'), ('TRRMVBR128F92F64BA', 'TRMEBVU128F92F64DB', 'TRISTGF12903D0DC6F'), ('TRRMVBR128F92F64BA', 'TRUYKXX128F426C2F1', 'TRISTGF12903D0DC6F'), ('TRWCIAX128F42925BD', 'TRRGKHJ128F92F64DA', 'TRHUNZT128C719654E'), ('TRWCIAX128F42925BD', 'TRRGKHJ128F92F64DA', 'TRMEBVU128F92F64DB'), ('TRWCIAX128F42925BD', 'TRRGKHJ128F92F64DA', 'TRUYKXX128F426C2F1'), ('TRWCIAX128F42925BD', 'TRRGKHJ128F92F64DA', 'TRISTGF12903D0DC6F'), ('TRWCIAX128F42925BD', 'TRHUNZT128C719654E', 'TRMEBVU128F92F64DB'), ('TRWCIAX128F42925BD', 'TRHUNZT128C719654E', 'TRUYKXX128F426C2F1'), ('TRWCIAX128F42925BD', 'TRHUNZT128C719654E', 'TRISTGF12903D0DC6F'), ('TRWCIAX128F42925BD', 'TRMEBVU128F92F64DB', 'TRUYKXX128F426C2F1'), ('TRWCIAX128F42925BD', 'TRMEBVU128F92F64DB', 'TRISTGF12903D0DC6F'), ('TRWCIAX128F42925BD', 'TRUYKXX128F426C2F1', 'TRISTGF12903D0DC6F'), ('TRRGKHJ128F92F64DA', 'TRHUNZT128C719654E', 'TRMEBVU128F92F64DB'), ('TRRGKHJ128F92F64DA', 'TRHUNZT128C719654E', 'TRUYKXX128F426C2F1'), ('TRRGKHJ128F92F64DA', 'TRHUNZT128C719654E', 'TRISTGF12903D0DC6F'), ('TRRGKHJ128F92F64DA', 'TRMEBVU128F92F64DB', 'TRUYKXX128F426C2F1'), ('TRRGKHJ128F92F64DA', 'TRMEBVU128F92F64DB', 'TRISTGF12903D0DC6F'), ('TRRGKHJ128F92F64DA', 'TRUYKXX128F426C2F1', 'TRISTGF12903D0DC6F'), ('TRHUNZT128C719654E', 'TRMEBVU128F92F64DB', 'TRUYKXX128F426C2F1'), ('TRHUNZT128C719654E', 'TRMEBVU128F92F64DB', 'TRISTGF12903D0DC6F'), ('TRHUNZT128C719654E', 'TRUYKXX128F426C2F1', 'TRISTGF12903D0DC6F'), ('TRMEBVU128F92F64DB', 'TRUYKXX128F426C2F1', 'TRISTGF12903D0DC6F'), ('TRHMVOQ128F1472E6D', 'TRAYVEL128F149F631', 'TRFKZHE128F149F632'), ('TROVEVL128F932A447', 'TRHMVOQ128F1472E6D', 'TRAYVEL128F149F631'), ('TROVEVL128F932A447', 'TRAYVEL128F149F631', 'TRFKZHE128F149F632'), ('TRRMVBR128F92F64BA', 'TRZNGII128C7196554', 'TRWCIAX128F42925BD'), ('TRRMVBR128F92F64BA', 'TRZNGII128C7196554', 'TRRGKHJ128F92F64DA'), ('TRRMVBR128F92F64BA', 'TRZNGII128C7196554', 'TRHUNZT128C719654E'), ('TRRMVBR128F92F64BA', 'TRZNGII128C7196554', 'TRMEBVU128F92F64DB'), ('TRRMVBR128F92F64BA', 'TRZNGII128C7196554', 'TRISTGF12903D0DC6F'), ('TRZNGII128C7196554', 'TRHUNZT128C719654E', 'TRMEBVU128F92F64DB'), ('TRZNGII128C7196554', 'TRHUNZT128C719654E', 'TRISTGF12903D0DC6F'), ('TRZNGII128C7196554', 'TRMEBVU128F92F64DB', 'TRISTGF12903D0DC6F'), ('TRRMVBR128F92F64BA', 'TRWCIAX128F42925BD', 'TRUEQWJ128F421CD83'), ('TRRMVBR128F92F64BA', 'TRRGKHJ128F92F64DA', 'TRUEQWJ128F421CD83'), ('TRRMVBR128F92F64BA', 'TRHUNZT128C719654E', 'TRUEQWJ128F421CD83'), ('TRRMVBR128F92F64BA', 'TRUEQWJ128F421CD83', 'TRISTGF12903D0DC6F'), ('TRWCIAX128F42925BD', 'TRHUNZT128C719654E', 'TRUEQWJ128F421CD83'), ('TRRGKHJ128F92F64DA', 'TRHUNZT128C719654E', 'TRUEQWJ128F421CD83'), ('TRHUNZT128C719654E', 'TRMEBVU128F92F64DB', 'TRUEQWJ128F421CD83'), ('TRHUNZT128C719654E', 'TRUEQWJ128F421CD83', 'TRISTGF12903D0DC6F'), ('TRMEBVU128F92F64DB', 'TRUEQWJ128F421CD83', 'TRISTGF12903D0DC6F'), ('TRIPUHC12903D03AFC', 'TRBARSX12903D03AE5', 'TRWTPYD12903D03AE9'), ('TRGGDOF12903D03AEE', 'TRDBYEH12903D03AF3', 'TRIPUHC12903D03AFC'), ('TRGGDOF12903D03AEE', 'TRDBYEH12903D03AF3', 'TRWTPYD12903D03AE9'), ('TRGGDOF12903D03AEE', 'TRIPUHC12903D03AFC', 'TRWTPYD12903D03AE9'), ('TRDBYEH12903D03AF3', 'TRIPUHC12903D03AFC', 'TRBARSX12903D03AE5'), ('TRDBYEH12903D03AF3', 'TRIPUHC12903D03AFC', 'TRWTPYD12903D03AE9'), ('TRLUROI128F92FFBFD', 'TRUDNRB128F42598CA', 'TRLOHWT128F42598CF'), ('TRXHAZS128F42598D1', 'TRZLEQU128F4259AFD', 'TRUDNRB128F42598CA'), ('TRXHAZS128F42598D1', 'TRZLEQU128F4259AFD', 'TRLOHWT128F42598CF'), ('TRXHAZS128F42598D1', 'TRUDNRB128F42598CA', 'TRLOHWT128F42598CF'), ('TRZLEQU128F4259AFD', 'TRUDNRB128F42598CA', 'TRLOHWT128F42598CF')]\n",
      "Results saved for cluster 1 to Data/Results/cluster_1_results.csv\n",
      "Processing df_basket_2...\n",
      "Frequent Single Items: [('TRXNVAQ128F93176BA',), ('TROMKCG128F9320C09',), ('TRQFICK128F92F5190',), ('TRPBCPV128F9302770',), ('TRXXXDE12903CAE130',), ('TRCFRTP128F930276F',), ('TROTJAW128F1466DCE',), ('TRVLXMQ128F9339980',), ('TRGFQXC128F92F3C37',), ('TRJNGBW128F930276C',), ('TRFPEPB128F92EBCB8',), ('TRSIKBL128F427F430',), ('TRXHLUP128F9320B70',), ('TRGNTLG12903CF25D9',), ('TRHCIJJ128F9305C8A',), ('TRRNZBN128F147CC7A',), ('TRRMNLW128F92D92B0',), ('TRBIZJO128F4259F57',), ('TRZFXSA128F93073BE',), ('TRUPDNU128F147CBE9',), ('TRPQPVO128F1460295',), ('TRGZAEU128E078393F',), ('TRUNRBL128F92D92AC',), ('TRDGUAJ128F92D541D',), ('TRBYSLP128F147CC94',), ('TRWSXPD128F4259F3B',), ('TRFMXJI128F930738B',), ('TRWKOEO128F147CC66',), ('TRHOEPA128F4259F3F',), ('TRUQERG128F147CBEA',), ('TRFLVKB128F147CC69',), ('TRBKSWQ128F4259F3C',), ('TRNRTQT128F4259F55',), ('TREAYDQ128F147CC6C',), ('TRJRIHX128F147CBC5',), ('TRUNYCG128F423A553',), ('TRUIIPM128F147CBD2',), ('TRYDIVP12903CAF5A7',), ('TRTAMNT128E07926F7',), ('TRAFMVN128F147CBCE',), ('TRDRTNQ128F93313A3',), ('TRVBFHW128F147CC96',), ('TRLNLYC128F422B8D2',), ('TRFCHEY128E079219C',), ('TRLVJWO128F426B41E',), ('TRRGPSF128F92D92AA',), ('TREJRVZ128F932732E',), ('TRDLLJO128F93216EA',), ('TRPZIII128F92D5420',), ('TRZEWHX128F92D92B3',), ('TRSFLLX128F932732F',), ('TRHDWRL128E079533D',), ('TRWKVYN128F146247D',), ('TRFUOFT128F4253DC8',), ('TRSMQXY128F93216E3',), ('TREGXCG128F930277B',), ('TRXLACM128F427FD9D',), ('TRSOYEJ128F149895A',), ('TRHTTQE128F9305C89',), ('TRHYDRB128F427FDA6',), ('TRUXLYQ128F426B41C',), ('TRKQTTP128EF34337D',), ('TRCNIME128E0799376',), ('TRPEGDQ128F423B914',), ('TRFYIGG128F148D102',), ('TRYQEML128F9320B6A',), ('TRSKQZQ12903CAF5A3',), ('TRILQPW128F92E2887',), ('TRPZMCK128F934C24E',), ('TREYLBG128F934B6EA',), ('TRZQTVH128F934B6E3',), ('TRKNWGD128F934B6E5',), ('TRILNPM128F92EBA22',), ('TRKZCVA128F42AC2D3',), ('TRPGPDK12903CCC651',), ('TRAALAH128E078234A',), ('TRTDKMT128F92CDD87',), ('TRWVOJJ12903CCC654',), ('TRQUYSJ128F92EA2E3',), ('TRYALRP128F92F521E',), ('TRDRAHQ128F427FE50',), ('TRWCCRR128F935A65A',), ('TRMJSHT128F422A802',), ('TRKKBJS128F92EF7D2',), ('TRIPAUX128F934B53F',), ('TRDUXSE128F4280051',), ('TRPDWYO128F422EF38',), ('TRUMENS12903CF265E',), ('TRRHMCH12903CEC792',), ('TRQQDTN128F92F9B18',), ('TRJCTNF12903CF4558',), ('TRWQUED128F1482B7A',), ('TRFNJJG128F428E48F',), ('TRMLTQI128F93115BD',), ('TRBCLDH128F4293B4F',), ('TRWAQOC12903CB84CA',), ('TRKBAHH128F4291075',), ('TRXAKHE128F4280052',), ('TRHOXJK128F14A13F2',), ('TRMDBUA128F14A13EE',), ('TRISISN128F931F1BD',), ('TRZOXGD128F931F1B6',), ('TRGUSWI128F92EBA20',), ('TRZJFZJ128F92D425E',), ('TRJRDCZ128F427FC25',), ('TRKPWWP128F1491B8D',), ('TRUHYNC128F92E288A',), ('TRDHNBY128F42B8688',), ('TRPCZPE12903CAF5BD',), ('TRPCREI128F429106F',), ('TRWSPRQ128F14A13FA',), ('TRPTIVU12903CAF5D2',), ('TRHTZBY12903CAF5B9',), ('TRDHVPL12903CAF5AE',), ('TRRRMKC128E0792990',), ('TRJCWWB128F429106E',), ('TREBAMB128F930C1B0',), ('TROXVFQ128F930BD41',), ('TRBZDMX128F934B682',), ('TRFSHWM128F934B386',), ('TRNHRRE128F934B687',), ('TRYTNRN12903CF258E',), ('TRVUGOX128E0784629',), ('TRKBRXQ128F934B997',), ('TRGMHGM128F934B38A',), ('TRRAMCS128F934B99D',), ('TRXUVJK128F934B383',), ('TRRWOUG12903CF05E9',), ('TRRJGQU128F934B53C',), ('TRRORKI128F428F9F9',), ('TRIPTUT128F428F9FB',), ('TROOMUK128F42BA19C',), ('TRMPKTQ12903CAF5C1',), ('TRDLJYE12903CAF5C8',), ('TRGKZEQ12903CAF5D8',), ('TRLRGVX128E078EC1B',), ('TRUFTBY128F93450B8',), ('TRBSJUP128F1482B7D',), ('TRZZEVQ128F92CFD63',), ('TRIDQJA12903CE29CC',), ('TRDKTRW128F1480A28',), ('TRONYHY128F92C9D11',), ('TRPFYYL128F92F7144',), ('TRSUSWW128F93463BF',), ('TRQRWWM128F42601A3',), ('TRVSGUV128F1482B7B',), ('TRVIEFP128F4293B56',), ('TRBGMGC128F4293B53',), ('TRNUQCB128F4293B51',), ('TRZJBDY128F4293B52',), ('TRXEAGI128F42408AC',), ('TRYJCJN128F4293B55',), ('TROVGXW128F92F9B1D',), ('TRTRUJU128F1482B74',), ('TRMVCUH128F92D1373',), ('TRBAKDS128F428F9FD',), ('TRLXTNA128F933B51A',), ('TRYCHKX128F930CD29',), ('TREUNFY128F4293B50',)]\n",
      "Frequent Pairs: [('TRPBCPV128F9302770', 'TRRMNLW128F92D92B0'), ('TROTJAW128F1466DCE', 'TRFPEPB128F92EBCB8'), ('TRXXXDE12903CAE130', 'TRXHLUP128F9320B70'), ('TRFMXJI128F930738B', 'TRZFXSA128F93073BE'), ('TRUNRBL128F92D92AC', 'TRRMNLW128F92D92B0'), ('TRZFXSA128F93073BE', 'TREAYDQ128F147CC6C'), ('TRZFXSA128F93073BE', 'TRWKOEO128F147CC66'), ('TRZFXSA128F93073BE', 'TRUQERG128F147CBEA'), ('TRUPDNU128F147CBE9', 'TREAYDQ128F147CC6C'), ('TRUPDNU128F147CBE9', 'TRUQERG128F147CBEA'), ('TREAYDQ128F147CC6C', 'TRWKOEO128F147CC66'), ('TREAYDQ128F147CC6C', 'TRUQERG128F147CBEA'), ('TRWKOEO128F147CC66', 'TRUQERG128F147CBEA'), ('TRBYSLP128F147CC94', 'TRUQERG128F147CBEA'), ('TRDRTNQ128F93313A3', 'TRFMXJI128F930738B'), ('TRDRTNQ128F93313A3', 'TRZFXSA128F93073BE'), ('TRDRTNQ128F93313A3', 'TRWKOEO128F147CC66'), ('TRDRTNQ128F93313A3', 'TRUIIPM128F147CBD2'), ('TRDRTNQ128F93313A3', 'TRAFMVN128F147CBCE'), ('TRLVJWO128F426B41E', 'TRFUOFT128F4253DC8'), ('TRLVJWO128F426B41E', 'TRXLACM128F427FD9D'), ('TRFUOFT128F4253DC8', 'TRXLACM128F427FD9D'), ('TRFUOFT128F4253DC8', 'TRCNIME128E0799376'), ('TRXLACM128F427FD9D', 'TRCNIME128E0799376'), ('TRDRTNQ128F93313A3', 'TRUPDNU128F147CBE9'), ('TRDRTNQ128F93313A3', 'TREAYDQ128F147CC6C'), ('TRDRTNQ128F93313A3', 'TRBYSLP128F147CC94'), ('TRDRTNQ128F93313A3', 'TRUQERG128F147CBEA'), ('TRILQPW128F92E2887', 'TRKKBJS128F92EF7D2'), ('TRILQPW128F92E2887', 'TRGUSWI128F92EBA20'), ('TRKKBJS128F92EF7D2', 'TRGUSWI128F92EBA20'), ('TRKPWWP128F1491B8D', 'TRILQPW128F92E2887'), ('TRILQPW128F92E2887', 'TRUHYNC128F92E288A'), ('TRKKBJS128F92EF7D2', 'TRUHYNC128F92E288A'), ('TRUHYNC128F92E288A', 'TRGUSWI128F92EBA20'), ('TRSKQZQ12903CAF5A3', 'TRYDIVP12903CAF5A7'), ('TRZFXSA128F93073BE', 'TRRNZBN128F147CC7A'), ('TRRNZBN128F147CC7A', 'TREAYDQ128F147CC6C'), ('TRRNZBN128F147CC7A', 'TRUQERG128F147CBEA'), ('TRUQERG128F147CBEA', 'TRAFMVN128F147CBCE'), ('TRUPDNU128F147CBE9', 'TRUIIPM128F147CBD2'), ('TRUQERG128F147CBEA', 'TRUIIPM128F147CBD2'), ('TRXXXDE12903CAE130', 'TRLXTNA128F933B51A'), ('TRLXTNA128F933B51A', 'TRXHLUP128F9320B70'), ('TREAYDQ128F147CC6C', 'TRUIIPM128F147CBD2')]\n",
      "Frequent Triplets: [('TRDRTNQ128F93313A3', 'TRUQERG128F147CBEA', 'TREAYDQ128F147CC6C'), ('TRILQPW128F92E2887', 'TRGUSWI128F92EBA20', 'TRKKBJS128F92EF7D2')]\n",
      "Results saved for cluster 2 to Data/Results/cluster_2_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary for all baskets\n",
    "df_baskets = {f\"df_basket_{i}\": globals()[f\"df_basket_{i}\"] for i in range(1, 3)}\n",
    "\n",
    "min_support = 0.02\n",
    "\n",
    "# Process each basket and save results\n",
    "for i, (name, data) in enumerate(df_baskets.items(), start=1):\n",
    "    print(f\"Processing {name}...\")\n",
    "    frequent_itemsets = apriori_pairs_and_triplets(data, min_support)\n",
    "    \n",
    "    # Convert frequent itemsets to a DataFrame\n",
    "    results_df = pd.DataFrame(\n",
    "        [{\"itemset\": itemset, \"support\": support} for itemset, support in frequent_itemsets.items()]\n",
    "    )\n",
    "    \n",
    "    # Save each result DataFrame with a unique name\n",
    "    output_file = f\"Data/Results/cluster_{i}_results.csv\"  # Use the index 'i' for unique filenames\n",
    "    results_df.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved for cluster {i} to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the results: Final songs recommendations\n",
    "- Heatmap showing the support between pairs of songs (duplets)\n",
    "- Network graph showing triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cluster_1_results.csv...\n",
      "Support heatmap saved to Data/Heatmaps/cluster_1_results_heatmap.png\n",
      "['Alejandro', 'Babyfather', 'Back to Black', 'Be That Easy', 'Call Me When You Get This', 'Can U Believe', 'Choux Pastry Heart', 'Halo', 'I Heard Love Is Blind', 'In Another Time', 'Intro / Stronger Than Me', \"It Don't Have to Change\", 'Know You Now', 'Like A Tattoo', 'Long Hard Road', 'Love Is Stronger Than Pride', 'Morning Bird', 'Nothing Can Come Between Us', 'October Song', 'Put Your Records On', 'Save Room', 'Smooth Operator', 'Some Unholy War', 'Stronger Than Me', 'Teach U a Lesson', 'Trouble Sleeping', 'Wake Up Alone', 'What Is It About Men', 'When Am I Going To Make A Living', 'You Sent Me Flying / Cherry']\n",
      "Similarity heatmap saved to Data/Heatmaps/cluster_1_results_similarity_heatmap.png\n",
      "Processing cluster_2_results.csv...\n",
      "Support heatmap saved to Data/Heatmaps/cluster_2_results_heatmap.png\n",
      "['5.45', 'Am I Evil?', 'Broken, Beat & Scarred', 'Bye Bye Beautiful', 'Chapter Four', 'Deliver Us From Evil', 'Ever Dream', 'Fade to Black', 'Feuer Frei', 'Links 2 3 4', 'Meet the Monster', 'My Own Hell', 'Nemo', 'Ride the Lightning', 'Room 409', 'Rosenrot', 'Scream Aim Fire', 'Servant in Heaven - King in Hell', 'Stranger than Fiction', \"Tears Don't Fall\", 'The Call of Ktulu', 'The God That Failed', 'The Islander', 'The Thing That Should Not Be', 'The Unforgiven II', 'The Unforgiven III', 'Unholy Confessions', 'Until It Sleeps', 'Waking the Demon', 'Welcome Home (Sanitarium)']\n",
      "Similarity heatmap saved to Data/Heatmaps/cluster_2_results_similarity_heatmap.png\n"
     ]
    }
   ],
   "source": [
    "# Placeholder similarity measure function\n",
    "def calculate_similarity(song1, song2):\n",
    "    # Replace this with the actual similarity measure\n",
    "    return np.random.rand()  # Random similarity for demonstration purposes\n",
    "\n",
    "# Function to process a single file for heatmaps and graphs\n",
    "def process_csv(file_path, id_to_name):\n",
    "    # Load duplets and their support values\n",
    "    df = pd.read_csv(file_path)\n",
    "    duplets = {\n",
    "        tuple(item.strip() for item in row[\"itemset\"].strip(\"()\").replace(\"'\", \"\").split(\", \")): row[\"support\"]\n",
    "        for _, row in df.iterrows()\n",
    "    }\n",
    "\n",
    "    # Convert duplets' track_ids to names, handling missing keys\n",
    "    duplets_with_names = {\n",
    "        tuple(id_to_name.get(item, f\"Unknown({item})\") for item in duplet): support\n",
    "        for duplet, support in duplets.items()\n",
    "    }\n",
    "\n",
    "    # Filter out pairs including 'Revelry' and ensure only pairs are included\n",
    "    filtered_dublets = {\n",
    "        pair: support for pair, support in duplets_with_names.items()\n",
    "        if 'Revelry' not in pair and len(pair) == 2\n",
    "    }\n",
    "\n",
    "    # Prepare data for support heatmap\n",
    "    songs = sorted(list(set([item for pair in filtered_dublets.keys() for item in pair])))  # Derived from filtered_dublets\n",
    "    heatmap_data = pd.DataFrame(0, index=songs, columns=songs)\n",
    "\n",
    "    for (song1, song2), support in filtered_dublets.items():\n",
    "        heatmap_data.loc[song1, song2] = support\n",
    "        heatmap_data.loc[song2, song1] = support  # Symmetric pairs\n",
    "\n",
    "    # Save the support heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(\n",
    "        heatmap_data,\n",
    "        annot=False,\n",
    "        cmap=\"Blues\",\n",
    "        cbar_kws={'label': 'Support'}\n",
    "    )\n",
    "    plt.title(f\"Song Pair Support Heatmap - {os.path.basename(file_path)}\", fontsize=16)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    heatmap_path = os.path.join(output_dir_heatmaps, f\"{os.path.basename(file_path).replace('.csv', '')}_heatmap.png\")\n",
    "    plt.savefig(heatmap_path)\n",
    "    plt.close()\n",
    "    print(f\"Support heatmap saved to {heatmap_path}\")\n",
    "\n",
    "    # Reuse only the songs from the support heatmap\n",
    "    songs_from_support = heatmap_data.index.tolist()  # Use exactly the same songs as in the support heatmap\n",
    "    print(songs_from_support)\n",
    "\n",
    "    # Prepare data for similarity heatmap\n",
    "    similarity_matrix = np.zeros((len(songs_from_support), len(songs_from_support)))\n",
    "    for i, song1 in enumerate(songs_from_support):\n",
    "        for j, song2 in enumerate(songs_from_support):\n",
    "            if i <= j:  # Compute only upper triangular and diagonal\n",
    "                similarity_matrix[i, j] = calculate_similarity(song1, song2)\n",
    "                similarity_matrix[j, i] = similarity_matrix[i, j]  # Symmetric matrix\n",
    "\n",
    "    similarity_df = pd.DataFrame(similarity_matrix, index=songs_from_support, columns=songs_from_support)\n",
    "\n",
    "    # Save the similarity heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(\n",
    "        similarity_df,\n",
    "        annot=False,\n",
    "        cmap=\"coolwarm\",\n",
    "        cbar_kws={'label': 'Similarity'},\n",
    "        xticklabels=True,\n",
    "        yticklabels=True\n",
    "    )\n",
    "    plt.title(f\"Song Similarity Heatmap - {os.path.basename(file_path)}\", fontsize=16)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    similarity_heatmap_path = os.path.join(output_dir_heatmaps, f\"{os.path.basename(file_path).replace('.csv', '')}_similarity_heatmap.png\")\n",
    "    plt.savefig(similarity_heatmap_path)\n",
    "    plt.close()\n",
    "    print(f\"Similarity heatmap saved to {similarity_heatmap_path}\")\n",
    "\n",
    "# Directories for input and output\n",
    "input_dir = \"Data/Results\"\n",
    "output_dir_heatmaps = \"Data/Heatmaps\"\n",
    "os.makedirs(output_dir_heatmaps, exist_ok=True)\n",
    "\n",
    "# Define the mapping of track IDs to names, normalizing keys\n",
    "id_to_name = {track_id.strip(): name for track_id, name in df_songs.set_index('track_id')['name'].to_dict().items()}\n",
    "\n",
    "# Process each CSV file in the input directory\n",
    "for file_name in os.listdir(input_dir):\n",
    "    if file_name.endswith(\".csv\"):  # Process only CSV files\n",
    "        file_path = os.path.join(input_dir, file_name)\n",
    "        print(f\"Processing {file_name}...\")\n",
    "        process_csv(file_path, id_to_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing graph for cluster_1_results.csv...\n",
      "Graph saved for cluster 1 to Data/Graphs/cluster_1_results_group_1.png\n",
      "Graph saved for cluster 2 to Data/Graphs/cluster_1_results_group_2.png\n",
      "Graph saved for cluster 3 to Data/Graphs/cluster_1_results_group_3.png\n",
      "Graph saved for cluster 4 to Data/Graphs/cluster_1_results_group_4.png\n",
      "Graph saved for cluster 5 to Data/Graphs/cluster_1_results_group_5.png\n",
      "Graph saved for cluster 6 to Data/Graphs/cluster_1_results_group_6.png\n",
      "Graph saved for cluster 7 to Data/Graphs/cluster_1_results_group_7.png\n",
      "Processing graph for cluster_2_results.csv...\n",
      "Graph saved for cluster 1 to Data/Graphs/cluster_2_results_group_1.png\n",
      "Graph saved for cluster 2 to Data/Graphs/cluster_2_results_group_2.png\n",
      "Graph saved for cluster 3 to Data/Graphs/cluster_2_results_group_3.png\n",
      "Graph saved for cluster 4 to Data/Graphs/cluster_2_results_group_4.png\n",
      "Graph saved for cluster 5 to Data/Graphs/cluster_2_results_group_5.png\n",
      "Graph saved for cluster 6 to Data/Graphs/cluster_2_results_group_6.png\n",
      "Graph saved for cluster 7 to Data/Graphs/cluster_2_results_group_7.png\n"
     ]
    }
   ],
   "source": [
    "def create_graph_from_results(file_path, id_to_name, output_dir_graphs):\n",
    "    # Load the results file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Extract triplets and map track IDs to names\n",
    "    triplets = {\n",
    "        tuple(item.strip() for item in row[\"itemset\"].strip(\"()\").replace(\"'\", \"\").split(\", \")): row[\"support\"]\n",
    "        for _, row in df.iterrows()\n",
    "    }\n",
    "    triplets_with_names = [\n",
    "        tuple(id_to_name.get(item, f\"Unknown({item})\") for item in triplet)\n",
    "        for triplet in triplets.keys()\n",
    "    ]\n",
    "\n",
    "    # Create the graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add edges for each triplet\n",
    "    for triplet in triplets_with_names:\n",
    "        for pair in combinations(triplet, 2):\n",
    "            G.add_edge(pair[0], pair[1])\n",
    "\n",
    "    # Identify connected components (clusters)\n",
    "    groups = [G.subgraph(c).copy() for c in nx.connected_components(G)]\n",
    "\n",
    "    # Plot each cluster\n",
    "    for i, group in enumerate(groups):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        pos = nx.spring_layout(group, seed=42)  # Use spring layout for neat arrangement\n",
    "        nx.draw_networkx_nodes(group, pos, node_size=1000, node_color='skyblue', alpha=0.9)\n",
    "        nx.draw_networkx_edges(group, pos, width=2, edge_color='gray', alpha=0.6)\n",
    "        nx.draw_networkx_labels(group, pos, font_size=10, font_color='black')\n",
    "        plt.title(f\"Group {i + 1} - {os.path.basename(file_path)}\", fontsize=14)\n",
    "        plt.axis('off')  # Turn off axes\n",
    "\n",
    "        # Save the graph visualization\n",
    "        graph_path = os.path.join(output_dir_graphs, f\"{os.path.basename(file_path).replace('.csv', '')}_group_{i + 1}.png\")\n",
    "        plt.savefig(graph_path)\n",
    "        plt.close()\n",
    "        print(f\"Graph saved for cluster {i + 1} to {graph_path}\")\n",
    "\n",
    "# Example usage\n",
    "output_dir_graphs = \"Data/Graphs\"\n",
    "os.makedirs(output_dir_graphs, exist_ok=True)\n",
    "\n",
    "# Process each results file\n",
    "input_dir = \"Data/Results\"\n",
    "id_to_name = {track_id.strip(): name for track_id, name in df_songs.set_index('track_id')['name'].to_dict().items()}  # Define mapping\n",
    "\n",
    "for file_name in os.listdir(input_dir):\n",
    "    if file_name.endswith(\".csv\"):  # Process only CSV files\n",
    "        file_path = os.path.join(input_dir, file_name)\n",
    "        print(f\"Processing graph for {file_name}...\")\n",
    "        create_graph_from_results(file_path, id_to_name, output_dir_graphs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
